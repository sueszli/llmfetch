Core flow:

- User enters a URL and defines what data they want to extract (schema)
- System fetches the page content
- LLM processes the raw data and extracts structured data matching the schema
- Results are displayed in a clean, usable format

Features:

- Web server that supports CRUD operations for create/update/delete/list of scrapers.
- Scraping engine that fetches HTML from a given website and processes it with an LLM to extract structured data.
- database for storing stuff
- Next.js + React for the frontend ----> skip this for now

make sure to have high code locality, use elegant and simple functions and keep things short and simple, just like you would in haskell / C. inline functions that are too short.
